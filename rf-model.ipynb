{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('cleandf.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cur</th>\n",
       "      <th>description</th>\n",
       "      <th>favorites</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>images</th>\n",
       "      <th>overview</th>\n",
       "      <th>price</th>\n",
       "      <th>script</th>\n",
       "      <th>title</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>materials</th>\n",
       "      <th>gold</th>\n",
       "      <th>silver</th>\n",
       "      <th>diamond</th>\n",
       "      <th>brass</th>\n",
       "      <th>vintage</th>\n",
       "      <th>year</th>\n",
       "      <th>handmade</th>\n",
       "      <th>desc</th>\n",
       "      <th>adesc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USD</td>\n",
       "      <td>24 weightgpc 735 grams width links 21mm 20 inc...</td>\n",
       "      <td>3737.0</td>\n",
       "      <td>[https://i.etsystatic.com/9408646/r/il/89302d/...</td>\n",
       "      <td>[{'url': 'https://i.etsystatic.com/9408646/r/i...</td>\n",
       "      <td>[\\n    Handmade item\\n, \\n    Materials: Solid...</td>\n",
       "      <td>15.00</td>\n",
       "      <td>[\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...</td>\n",
       "      <td>Sterling silver chain Necklace, Mens chain, Cu...</td>\n",
       "      <td>573.0</td>\n",
       "      <td>solid 925 sterling silver italian chain if wan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>24 735 links 21mm 20 1300 links 395mm figaro 1...</td>\n",
       "      <td>links links figaro browse shop links cable cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USD</td>\n",
       "      <td>the package is sent via international register...</td>\n",
       "      <td>248.0</td>\n",
       "      <td>[https://i.etsystatic.com/7353734/r/il/d16bb4/...</td>\n",
       "      <td>[{'url': 'https://i.etsystatic.com/7353734/r/i...</td>\n",
       "      <td>[\\n    Handmade item\\n, \\n    Material: solid ...</td>\n",
       "      <td>26.00</td>\n",
       "      <td>[\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...</td>\n",
       "      <td>Name necklace. Silver name necklace. Personali...</td>\n",
       "      <td>464.0</td>\n",
       "      <td>solid sterling silver</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>package sent via international registered air ...</td>\n",
       "      <td>package sent via international registered air ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USD</td>\n",
       "      <td>example james 6 number is optional and can be ...</td>\n",
       "      <td>144.0</td>\n",
       "      <td>[https://i.etsystatic.com/6903082/r/il/e6e6d0/...</td>\n",
       "      <td>[{'url': 'https://i.etsystatic.com/6903082/r/i...</td>\n",
       "      <td>[\\n    Handmade item\\n, \\n    Can be personali...</td>\n",
       "      <td>57.99</td>\n",
       "      <td>[\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...</td>\n",
       "      <td>Volleyball Sport Charm 1.25\" Personalized with...</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>sterling silver silver rolo chain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>example james 6 number optional 2 digits perso...</td>\n",
       "      <td>example james number optional digits personali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>USD</td>\n",
       "      <td>this gemstone necklace features a gorgeous fac...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[https://i.etsystatic.com/13865545/r/il/16ab85...</td>\n",
       "      <td>[{'url': 'https://i.etsystatic.com/13865545/r/...</td>\n",
       "      <td>[\\n    Handmade item\\n, \\n    Necklace length:...</td>\n",
       "      <td>67.03</td>\n",
       "      <td>[\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...</td>\n",
       "      <td>Rainbow Moonstone Necklace Moonstone Pendant N...</td>\n",
       "      <td>242.0</td>\n",
       "      <td>silver stone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>gemstone necklace features gorgeous faceted dr...</td>\n",
       "      <td>gemstone necklace features gorgeous faceted dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>USD</td>\n",
       "      <td>precious and semi-precious gemstones have been...</td>\n",
       "      <td>3495.0</td>\n",
       "      <td>[https://i.etsystatic.com/9859922/r/il/9d1001/...</td>\n",
       "      <td>[{'url': 'https://i.etsystatic.com/9859922/r/i...</td>\n",
       "      <td>[\\n    Handmade item\\n, \\n    Materials: love,...</td>\n",
       "      <td>13.00</td>\n",
       "      <td>[\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...</td>\n",
       "      <td>Malachite Heart - malachite stone - healing cr...</td>\n",
       "      <td>18235.0</td>\n",
       "      <td>love light positive energy malachite malachite...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>precious semi-precious gemstones used since re...</td>\n",
       "      <td>precious semi-precious gemstones used since re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cur                                        description  favorites  \\\n",
       "0     USD  24 weightgpc 735 grams width links 21mm 20 inc...     3737.0   \n",
       "1     USD  the package is sent via international register...      248.0   \n",
       "10    USD  example james 6 number is optional and can be ...      144.0   \n",
       "100   USD  this gemstone necklace features a gorgeous fac...       28.0   \n",
       "1000  USD  precious and semi-precious gemstones have been...     3495.0   \n",
       "\n",
       "                                             image_urls  \\\n",
       "0     [https://i.etsystatic.com/9408646/r/il/89302d/...   \n",
       "1     [https://i.etsystatic.com/7353734/r/il/d16bb4/...   \n",
       "10    [https://i.etsystatic.com/6903082/r/il/e6e6d0/...   \n",
       "100   [https://i.etsystatic.com/13865545/r/il/16ab85...   \n",
       "1000  [https://i.etsystatic.com/9859922/r/il/9d1001/...   \n",
       "\n",
       "                                                 images  \\\n",
       "0     [{'url': 'https://i.etsystatic.com/9408646/r/i...   \n",
       "1     [{'url': 'https://i.etsystatic.com/7353734/r/i...   \n",
       "10    [{'url': 'https://i.etsystatic.com/6903082/r/i...   \n",
       "100   [{'url': 'https://i.etsystatic.com/13865545/r/...   \n",
       "1000  [{'url': 'https://i.etsystatic.com/9859922/r/i...   \n",
       "\n",
       "                                               overview  price  \\\n",
       "0     [\\n    Handmade item\\n, \\n    Materials: Solid...  15.00   \n",
       "1     [\\n    Handmade item\\n, \\n    Material: solid ...  26.00   \n",
       "10    [\\n    Handmade item\\n, \\n    Can be personali...  57.99   \n",
       "100   [\\n    Handmade item\\n, \\n    Necklace length:...  67.03   \n",
       "1000  [\\n    Handmade item\\n, \\n    Materials: love,...  13.00   \n",
       "\n",
       "                                                 script  \\\n",
       "0     [\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...   \n",
       "1     [\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...   \n",
       "10    [\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...   \n",
       "100   [\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...   \n",
       "1000  [\\n    {\\n    \"@type\": \"Product\",\\n    \"@conte...   \n",
       "\n",
       "                                                  title  rating_count  \\\n",
       "0     Sterling silver chain Necklace, Mens chain, Cu...         573.0   \n",
       "1     Name necklace. Silver name necklace. Personali...         464.0   \n",
       "10    Volleyball Sport Charm 1.25\" Personalized with...        1729.0   \n",
       "100   Rainbow Moonstone Necklace Moonstone Pendant N...         242.0   \n",
       "1000  Malachite Heart - malachite stone - healing cr...       18235.0   \n",
       "\n",
       "                                              materials  gold  silver  \\\n",
       "0     solid 925 sterling silver italian chain if wan...   0.0     1.0   \n",
       "1                                 solid sterling silver   0.0     1.0   \n",
       "10                    sterling silver silver rolo chain   0.0     1.0   \n",
       "100                                        silver stone   0.0     1.0   \n",
       "1000  love light positive energy malachite malachite...   0.0     0.0   \n",
       "\n",
       "      diamond  brass  vintage  year  handmade  \\\n",
       "0         0.0    0.0        0   NaN         1   \n",
       "1         0.0    0.0        0   NaN         1   \n",
       "10        0.0    0.0        0   NaN         1   \n",
       "100       0.0    0.0        0   NaN         1   \n",
       "1000      0.0    0.0        0   NaN         1   \n",
       "\n",
       "                                                   desc  \\\n",
       "0     24 735 links 21mm 20 1300 links 395mm figaro 1...   \n",
       "1     package sent via international registered air ...   \n",
       "10    example james 6 number optional 2 digits perso...   \n",
       "100   gemstone necklace features gorgeous faceted dr...   \n",
       "1000  precious semi-precious gemstones used since re...   \n",
       "\n",
       "                                                  adesc  \n",
       "0     links links figaro browse shop links cable cha...  \n",
       "1     package sent via international registered air ...  \n",
       "10    example james number optional digits personali...  \n",
       "100   gemstone necklace features gorgeous faceted dr...  \n",
       "1000  precious semi-precious gemstones used since re...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6975"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 6975)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_cossim = np.load('d2v-cossim.npy')\n",
    "d2v_cossim = d2v_cossim.astype(np.float64)\n",
    "d2v_cossim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 6975)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cossim = np.load('img_cossim.npy')\n",
    "img_cossim = img_cossim.astype(np.float64)\n",
    "img_cossim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15\n",
    "\n",
    "np.putmask(d2v_cossim, d2v_cossim>1-eps,-1.)\n",
    "np.putmask(img_cossim, img_cossim>1-eps,-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullindd2v = np.argpartition(d2v_cossim, -5,axis=1)[:,-5:]\n",
    "fullindd2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1051, 3027, 6318, 2218, 2558])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullindd2v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topd2vsim = d2v_cossim[np.arange(d2v_cossim.shape[0])[:,None],fullindd2v]\n",
    "topd2vsim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_d2vsim=df['price'].values[fullindd2v]\n",
    "prices_d2vsim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://eli:elipgsql@localhost:5432/necklaces_db\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "# Define a database name (we're using a dataset on births, so we'll call it birth_db)\n",
    "# Set your postgres username/password, and connection specifics\n",
    "username = 'eli'\n",
    "password = 'elipgsql'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'necklaces_db'\n",
    "\n",
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "df.to_sql('necklaces_db',engine, if_exists='replace',dtype = \n",
    "                {'images':sqlalchemy.types.JSON, 'script':sqlalchemy.types.JSON})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index'] = np.arange(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.  , 26.  , 57.99, ...,  8.  , 22.  , 19.  ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to make queries using psycopg2\n",
    "con = None\n",
    "con = psycopg2.connect(database = 'necklaces_db', host='/var/run/postgresql', user = 'eli')\n",
    "\n",
    "# query:\n",
    "#items = ', '.join(str(k) for k in fullindd2v[0])\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT price FROM necklaces_db\n",
    "\"\"\" \n",
    "traindata_from_sql = pd.read_sql_query(sql_query,con)\n",
    "traindata_from_sql['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59. ,  35. , 275. ,  62.5,  84. ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata_from_sql['price'].values[fullindd2v[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1051, 3027, 6318, 2218, 2558])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullindd2v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24.,  56., 110.,  78.,  78.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].values[fullindd2v[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullindimg = np.argpartition(img_cossim, -5,axis=1)[:,-5:]\n",
    "fullindimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topimgsim = img_cossim[np.arange(img_cossim.shape[0])[:,None],fullindimg]\n",
    "topimgsim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_imgsim=df['price'].values[fullindimg]\n",
    "prices_imgsim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([topd2vsim,prices_d2vsim,topimgsim,prices_imgsim],axis=1)\n",
    "X.shape\n",
    "\n",
    "y = df['price'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6975, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def mape(y_true, y_pred):\n",
    "    rel_err = np.abs(y_true-y_pred)/y_true\n",
    "    return 100.0*np.mean(rel_err)\n",
    "\n",
    "mapescore = make_scorer(mape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 ms, sys: 8 ms, total: 68 ms\n",
      "Wall time: 684 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import logging\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "params = {'n_estimators':[50, 100, 250], 'max_features':['auto','sqrt'], 'min_samples_leaf':[1,2,4,7], 'min_samples_split':[2,4,5]}\n",
    "rf = RandomForestRegressor(oob_score=True)\n",
    "regr = GridSearchCV(rf, params, scoring=mapescore,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eli/anaconda3/envs/etsyapp/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.91 s, sys: 664 ms, total: 8.57 s\n",
      "Wall time: 6min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [50, 100, 250], 'max_features': ['auto', 'sqrt'], 'min_samples_leaf': [1, 2, 4, 7], 'min_samples_split': [2, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mape, greater_is_better=False), verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto',\n",
       " 'min_samples_leaf': 7,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto',\n",
       " 'min_samples_leaf': 7,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit = regr.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit = regr.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.0962852187623"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(y_train,y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.999784604329719"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(y_train,y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.238893978497245"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =  regr.best_estimator_.predict(X_test)\n",
    "mape(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.035207493426768"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =  regr.best_estimator_.predict(X_test)\n",
    "mape(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.2'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "wd = \"/home/eli/code/insight/etsy/etsyitems/\"\n",
    "with open(wd + \"rfimgd2vmodel-v202.obj\",\"wb\") as f:\n",
    "    dill.dump(regr.best_estimator_,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "wd = \"/home/eli/code/insight/etsy/etsyitems/\"\n",
    "with open(wd + \"rfimgd2vmodel.obj\",\"wb\") as f:\n",
    "    dill.dump(regr.best_estimator_,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5580, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eli/anaconda3/envs/etsyapp/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 s, sys: 248 ms, total: 4.93 s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr_d2v = GridSearchCV(rf, params, scoring=mapescore,n_jobs=-1)\n",
    "regr_d2v.fit(X_train[:,:10],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto',\n",
       " 'min_samples_leaf': 7,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_d2v.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_d2v.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.621205555116084"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fit = regr_d2v.best_estimator_.predict(X_train[:,:10])\n",
    "mape(y_train,y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.744265771789451"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fit = regr_d2v.best_estimator_.predict(X_train[:,:10])\n",
    "mape(y_train,y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.61430108802566"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =  regr_d2v.best_estimator_.predict(X_test[:,:10])\n",
    "mape(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.165004180203873"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =  regr_d2v.best_estimator_.predict(X_test[:,:10])\n",
    "mape(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wd + \"rfd2vmodel-v202.obj\",\"wb\") as f:\n",
    "    dill.dump(regr_d2v.best_estimator_,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wd + \"rfd2vmodel.obj\",\"wb\") as f:\n",
    "    dill.dump(regr_d2v.best_estimator_,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=100,oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=True, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59659433842766196"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60683142948235602"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_pred,y_act):\n",
    "    map_error = 100/len(y_pred)*np.sum(np.abs((y_pred-y_act)/y_act))\n",
    "    return map_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loge(y_pred,y_act):\n",
    "    log_error = 1/len(y_pred)*np.sum(np.abs(np.log(np.abs(y_pred/y_act))))\n",
    "    return log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17276697854616574"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loge(y_rf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "y_base_pred = np.repeat(scipy.stats.mode(y_train)[0][0],len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.mode(y_train)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92739226604063463"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loge(y_base_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72521060359063227"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mape(y_base_pred,y_test)-mape(y_rf,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.44189254355426"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(y_base_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.84978866540536"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(y_base_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "TEMP_FOLDER = \"/home/eli/code/insight/etsy/etsyitems/nlp3\"\n",
    "print('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTOR SPACE MODEL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "def normvec(vec):\n",
    "    normv = normalize(vec[:,np.newaxis], axis=0).ravel()\n",
    "    return normv\n",
    "\n",
    "normvec(np.array([1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(train_texts)\n",
    "dictionary.save(os.path.join(TEMP_FOLDER, 'necklaces.dict'))  # store the dictionary, for future reference\n",
    "#dictionary = corpora.dictionary.Dictionary.load(os.path.join(TEMP_FOLDER, 'necklaces.dict'))\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in train_texts]\n",
    "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'necklaces.mm'), corpus)\n",
    "#corpus = corpora.MmCorpus(os.path.join(TEMP_FOLDER, 'necklaces.mm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model\n",
    "tfidf.save(os.path.join(TEMP_FOLDER, 'necklacesmedmodel.tfidf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(tfidf[corpus]) # transform corpus to Tfidf space and index it\n",
    "index.save(os.path.join(TEMP_FOLDER, 'necklacesmedtfidfsim.index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test = [dictionary.doc2bow(text) for text in test_texts]\n",
    "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'necklacesmedtest.mm'), corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtraintfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtesttfidf = tfidf[corpus_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "def read_corpus(texts, tokens_only=False):\n",
    "    for i, text in enumerate(texts):\n",
    "        if tokens_only:\n",
    "            yield gensim.utils.simple_preprocess(' '.join(text))\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(' '.join(text)), [i])\n",
    "        \n",
    "\n",
    "train_corpus = list(read_corpus(train_texts))\n",
    "#test_corpus = list(read_corpus(test_texts, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40,dm=0, dbow_words=1)\n",
    "\n",
    "model.build_vocab(train_corpus)\n",
    "\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(os.path.join(TEMP_FOLDER, 'necklaces.d2v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X_tr_d2v = np.array([model.infer_vector(train_corpus[i].words, steps=40, alpha=0.025) for i in range(len(train_corpus))])\n",
    "\n",
    "#X_test_d2v = np.array([model.infer_vector(test_corpus[i], steps=40, alpha=0.025) for i in range(len(test_corpus))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('d2v-features',X_tr_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_d2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d2v_sims = cosine_similarity(X_tr_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('d2v-cossim',d2v_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Reads an image from a file, decodes it into a dense tensor, and resizes it\n",
    "# to a fixed shape.\n",
    "def _parse_function(filename):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string)\n",
    "    image_resized = tf.image.resize_images(image_decoded, [224, 224])\n",
    "    return image_resized\n",
    "\n",
    "# A vector of filenames.\n",
    "filenames = tf.constant([os.path.join('/home/eli/code/insight/etsy/etsyitems/imagesstore/',x[0]['path']) for x in data['images'].values])\n",
    "\n",
    "# `labels[i]` is the label for the image in `filenames[i].\n",
    "#labels = tf.constant([0, 37, ...])\n",
    "\n",
    "def create_dataset(filenames, batch_size=1):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.batch(batch_size)  # Batch size to use\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features = iterator.get_next()\n",
    "    return batch_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "#from tensorflow.keras.models import Model\n",
    "\n",
    "# define the CNN network\n",
    "# Here we are using 19 layer CNN -VGG19 and initialising it\n",
    "# with pretrained imagenet weights\n",
    "model = mobilenet_v2.MobileNetV2(weights='imagenet',include_top=False,pooling='avg')\n",
    "\n",
    "# Extract features from an arbitrary intermediate layer\n",
    "# like the block4 pooling layer in VGG19\n",
    "#model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "# load an image and preprocess it\n",
    "#img_path = 'elephant.jpg'\n",
    "#img = image.load_img(img_path, target_size=(224, 224))\n",
    "#x = image.img_to_array(img)\n",
    "#x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)\n",
    "\n",
    "# get the features \n",
    "#features = model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros((len(data),1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size=20\n",
    "i=0\n",
    "while (i+batch_size)<len(data):\n",
    "    next_batch = create_dataset(filenames[i:i+20], batch_size=batch_size)\n",
    "    with tf.Session() as sess:\n",
    "            first_batch = sess.run(next_batch)\n",
    "            images = preprocess_input(first_batch)\n",
    "    features[i:i+batch_size,:] = model.predict(images)\n",
    "    i+=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i=0\n",
    "features[i:i+20,:] = model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting and hyperparameter tuning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_r2(y_pred, y_act):\n",
    "    assert(len(y_pred)==len(y_act))\n",
    "    resid = y_pred-y_act\n",
    "    ssresid = np.sum(np.square(resid))\n",
    "    sstot = np.sum(np.square(y_act-np.mean(y_act)))\n",
    "    r2 = 1-ssresid/sstot\n",
    "    return r2\n",
    "\n",
    "def rmse(y_pred, y_act):\n",
    "    assert(len(y_pred)==len(y_act))\n",
    "    return np.sqrt(np.sum(np.square(y_pred-y_act))/len(y_act))\n",
    "\n",
    "def mape(y_pred, y_act):\n",
    "    assert(len(y_pred)==len(y_act))\n",
    "    return 100*np.sum(np.abs((y_pred-y_act)/y_act))/len(y_act)\n",
    "\n",
    "def adj_r2(y_est,y_act,dfest,dftot):\n",
    "    assert(len(y_est)==len(y_act))\n",
    "    resid = y_est-y_act\n",
    "    ssresid = np.sum(np.square(resid))\n",
    "    sstot = np.sum(np.square(y_act-np.mean(y_act)))\n",
    "    r2adj = 1-ssresid*dftot/sstot/dfest\n",
    "    return r2adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict_tfidf(k, X, y_train, weighting=False):\n",
    "    y_pred =  np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        sims = sorted(enumerate(index[X[i]]), key=lambda item: -item[1])[:k]\n",
    "        if weighting:\n",
    "            weights = np.square(normvec(np.array([v for (k,v) in sims])))\n",
    "            if np.array_equal(weights,np.zeros(len(weights))):\n",
    "                weights=None\n",
    "            y_pred[i] = np.average([y_train[k] for (k,v) in sims], weights=weights)\n",
    "        else:\n",
    "            y_pred[i] = np.average([y_train[k] for (k,v) in sims])\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparamcvknn_tfidf(klist, X, y, y_train):\n",
    "    results = []\n",
    "    for k in klist:\n",
    "        for weighting in [True]:\n",
    "            y_pred = knn_predict_tfidf(k, X, y_train, weighting)\n",
    "            results.append((adj_r2(y_pred, y, len(y)/k,len(y)-1),[k,weighting]))\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit = knn_predict_tfidf(10,Xtraintfidf,y_train,True)\n",
    "print(adj_r2(y_fit,y_train, len(y_train)/10,len(y_train)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(y_fit,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_predict_tfidf(10,Xtesttfidf,y_train,True)\n",
    "print(adj_r2(y_pred,y_test, len(y_test)/10,len(y_test)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(y_fit,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_testdata(X_test,y_test,y_train,params):\n",
    "    y_pred = knn_predict(params['k'],X_test,y_train,params['weighting'])\n",
    "    return score_r2(y_pred,y_test)\n",
    "                   \n",
    "params = {'k': 10, 'weighting': True}    \n",
    "print(score_testdata(Xtesttfidf, y_test,y_train,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def rmse_testdata(X_test,y_test,y_train,params):\n",
    "    y_pred = knn_predict(params['k'],X_test,y_train,params['weighting'])\n",
    "    return rmse(y_pred,y_test), y_pred\n",
    "                   \n",
    "params = {'k': 10, 'weighting': True}    \n",
    "rmse_test, y_predix = rmse_testdata(Xtesttfidf, y_test,y_train,params)\n",
    "print(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_rsquare(y_pred,y_act,N,k):\n",
    "    assert(len(y_pred)==len(y_act))\n",
    "    resid = y_pred-y_act\n",
    "    ssresid = np.sum(np.square(resid))\n",
    "    sstot = np.sum(np.square(y_act-np.mean(y_act)))\n",
    "    dftot = N-1\n",
    "    dfest = N/k\n",
    "    r2adj = 1-ssresid*dftot/sstot/dfest\n",
    "    return r2adj\n",
    "\n",
    "y_fit = knn_predict(10,Xtraintfidf, y_train,weighting=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_rsquare(y_fit,y_train,len(y_train),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(y_predix,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(10000):\n",
    "    sample= usdf.sample(n=10, random_state=i)\n",
    "    l.append(np.mean(sample['price'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = np.random.randint(6000)\n",
    "rmse(l[begin:(begin+len(y_test))],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_testdata(X_test,y_test,y_train,params):\n",
    "    y_pred = knn_predict(params['k'],X_test,y_train,params['weighting'])\n",
    "    return mape(y_pred,y_test)\n",
    "                   \n",
    "params = {'k': 10, 'weighting': True}    \n",
    "print(mape_testdata(Xtesttfidf, y_test,y_train,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict_w2v(k, X, y_train, weighting=False):\n",
    "    y_pred =  np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        #inferred_vector = model.infer_vector(X[i])\n",
    "        sims = model.docvecs.most_similar([X[i]], topn=k+1)[1:]\n",
    "        if weighting:\n",
    "            weights = np.square(normvec(np.array([v for (k,v) in sims])))\n",
    "            if np.array_equal(weights,np.zeros(len(weights))):\n",
    "                weights=None\n",
    "            y_pred[i] = np.average([y_train[k] for (k,v) in sims], weights=weights)\n",
    "        else:\n",
    "            y_pred[i] = np.average([y_train[k] for (k,v) in sims])\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparamcvknn_w2v(klist, X, y_act, y_train):\n",
    "    results = []\n",
    "    for k in klist:\n",
    "        for weighting in [True,False]:\n",
    "            y_pred = knn_predict_w2v(k, X, y_train, weighting)\n",
    "            results.append((rmse(y_pred, y_act),[k,weighting]))\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "klist=[3,5,7,10,15]\n",
    "w2v_hyperparam = hyperparamcvknn_w2v(klist, X_tr_d2v, y_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_d2v = knn_predict_w2v(7,X_test_d2v, y_train,weighting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(y_pred_d2v,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from time import time\n",
    "# Dimensionality reduction for tfidf\n",
    "def reduce_dim_by_svd(X, ncomp):\n",
    "    t0 = time()\n",
    "    svd = TruncatedSVD(ncomp)\n",
    "    X_res  = svd.fit_transform(X)\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(\n",
    "        int(explained_variance * 100)))\n",
    "    print()\n",
    "    return X_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils\n",
    "Xtrvec = matutils.corpus2csc(Xtraintfidf).T.toarray()\n",
    "Xtestvec = matutils.corpus2csc(Xtesttfidf).T.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_tfidf = reduce_dim_by_svd(Xtrvec, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst_tfidf = reduce_dim_by_svd(Xtestvec, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 50 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_random.cv_results_).sort_values(by='mean_test_score', ascending=False).iloc[21]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(n_estimators=100, max_features='auto')\n",
    "regr.fit(X_tr_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for training data: %0.2f\\n\" % regr.score(X_tr_tfidf,y_train))\n",
    "print(\"R2 for test data: %0.2f\\n\" % regr.score(X_tst_tfidf,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_tst_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_r2(y_pred,y_test,X_tst_tfidf.shape[1],len(y_pred)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "print(\"R2 for training data: %0.2f\\n\" % best_random.score(X_tr,y_train))\n",
    "print(\"R2 for test data: %0.2f\\n\" % best_random.score(X_tst,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_rsquare_rf(y_pred,y_act,npred):\n",
    "    assert(len(y_pred)==len(y_act))\n",
    "    resid = y_pred-y_act\n",
    "    ssresid = np.sum(np.square(resid))\n",
    "    sstot = np.sum(np.square(y_act-np.mean(y_act)))\n",
    "    dftot = len(y_act)-1\n",
    "    dfest = len(y_act)-npred-1\n",
    "    r2adj = 1-ssresid*dftot/sstot/dfest\n",
    "    return r2adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_random.cv_results_).sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit = best_random.predict(X_tr)\n",
    "adj_rsquare_rf(y_fit,y_train,X_tr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_rsquare_rf(y_pred,y_test,X_tst.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_random.predict(X_tst)\n",
    "\n",
    "print(rmse(y_pred,y_test))\n",
    "print(mape(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "def get_dmatrix(X, y):\n",
    "    return xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "dtrain_matrix = get_dmatrix(X_tr,y_train)\n",
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "eval_metric = [\"rmse\"]\n",
    "%time model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn=10\n",
    "y_pred = np.zeros(len(testvecs))\n",
    "for i in range(len(testvecs[:1])):\n",
    "    sims = sorted(enumerate(index[vec]), key=lambda item: -item[1])[:knn]\n",
    "    y_pred[i] = np.average([y_train[k] for (k,v) in sims], weights=np.square(vec_normalize([v for (k,v) in sims])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "trainvecs = tfidf[corpus]\n",
    "trainvecs = gensim.matutils.corpus2csc(trainvecs)\n",
    "trainvecs.T.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testvecs = [tfidf[dictionary.doc2bow(doc)] for doc in docs_test]\n",
    "testvecs = gensim.matutils.corpus2csc(testvecs)\n",
    "testvecs.T.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "n_neighbors = 10\n",
    "\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors, weights='distance')\n",
    "y_ = knn.fit(trainvecs, y_train).predict(testvecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(index[testvecs[0]]), key=lambda item: -item[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(vec_normalize([v for (k,v) in sorted(enumerate(index[testvecs[0]]), key=lambda item: -item[1])[:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "# Define a database name (we're using a dataset on births, so we'll call it birth_db)\n",
    "# Set your postgres username/password, and connection specifics\n",
    "username = 'eli'\n",
    "password = 'elipgsql'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'necklaces_train'\n",
    "\n",
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.DataFrame({'desc' : X_train, 'price' : y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.to_sql('necklaces_train',engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'necklaces_train'\n",
    "username = 'eli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT price FROM necklaces_train WHERE Index IN (%s) \n",
    "\"\"\" % items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to make queries using psycopg2\n",
    "con = None\n",
    "con = psycopg2.connect(database = db_name, host='/var/run/postgresql', user = username)\n",
    "\n",
    "# query:\n",
    "items = ', '.join(str(k) for k in l)\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT index, price FROM necklaces_train WHERE index IN (%s) \n",
    "\"\"\" % items\n",
    "traindata_from_sql = pd.read_sql_query(sql_query,con)\n",
    "len(traindata_from_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_from_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.square(vec_normalize([v for (k,v) in sims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_from_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightindexer for k in traindata_from_sql['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average([traindata_from_sql.loc[traindata_from_sql['index']==k, 'price'].values[0] for (k,v) in weightindexer],weights=[v for (k,v) in weightindexer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average([traindata_from_sql[traindata_from_sql['index']==k, 'price'] for (k,v) in sims], weights=np.square(vec_normalize([v for (k,v) in sims])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightindexer = list(zip([k for (k,v) in sims],weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(traindata_from_sql['price'].values,weights=np.square(vec_normalize([v for (k,v) in sims])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn=10\n",
    "y_pred = np.zeros(len(testvecs))\n",
    "for i in range(len(testvecs[:1])):\n",
    "    sims = sorted(enumerate(index[vec]), key=lambda item: -item[1])[:knn]\n",
    "    y_pred[i] = np.average([y_train[k] for (k,v) in sims], weights=np.square(vec_normalize([v for (k,v) in sims])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [k for (k,v) in sorted(enumerate(index[trainvecs[56]]), key=lambda item: -item[1])[1:knn+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "placeholder= '?' # For SQLite. See DBAPI paramstyle.\n",
    "items = ', '.join(str(k) for k in l)\n",
    "'SELECT name FROM students WHERE id IN (%s)' % items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'gold necklace'\n",
    "doc = text.split()\n",
    "vec = tfidf[dictionary.doc2bow(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = sorted(enumerate(index[vec]), key=lambda item: -item[1])[:knn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvecs = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn = 10\n",
    "y_fit = np.zeros(len(y_train))\n",
    "trainvecs = tfidf[corpus]\n",
    "for i in range(len(trainvecs[:1])):\n",
    "    sims = sorted(enumerate(index[]), key=lambda item: -item[1])[1:knn+1]\n",
    "    print(list(sims))\n",
    "    y_fit[i] = np.average([y_train[k] for (k,v) in sims], weights=np.square(vec_normalize([v for (k,v) in sims])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[y_train[k] for (k,v) in sims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(vec_normalize([v for (k,v) in sims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_from_sql['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = y_fit[~np.isnan(y_fit)]-y_train[~np.isnan(y_fit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sstot = np.sum(np.square(y_train[~np.isnan(y_fit)]-np.mean(y_train[~np.isnan(y_fit)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssresid = np.sum(np.square(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1-ssresid/sstot\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean(np.square(resid)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test[abs(resid)>1000], y_pred[abs(resid)>1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid[abs(resid)>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,15))\n",
    "sns.scatterplot(x=y_pred, y=resid, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(np.square(y_test-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.sort(np.square(y_test-y_pred))[:-100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[k] for (k,v) in sorted(enumerate(index[testvecs[0]]), key=lambda item: -item[1])[:5]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([y_train[k] for (k,v) in sorted(enumerate(index[testvecs[0]]), key=lambda item: -item[1])[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sorted(enumerate(index[vec]), key=lambda item: -item[1])[:5] for vec in testvecs[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = index[testvecs[0]]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in X_train:\n",
    "    for token in text.split():\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text.split() if frequency[token] > 1] for text in X_train]\n",
    "\n",
    "from pprint import pprint  # pretty-printer\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fdist = FreqDist(word for word in ' '.join(usdf['desc'].values).split() if not word.isnumeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.pprint(maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "usdf['adesc'] = usdf['desc'].apply(lambda desc: ' '.join([x for x in desc.split() if not bool(re.search(r'\\d', x))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "descs = usdf['adesc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf =  vectorizer.fit_transform(descs)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "denselist = tfidf.todense().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.inverse_transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdf[usdf.price>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidffeatures = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tfidffeatures.iloc[0]\n",
    "s[s>0].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "X_reduced = TruncatedSVD(n_components=50, random_state=0).fit_transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_embedded = TSNE(n_components=2, perplexity=40, verbose=2).fit_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(figsize=(10,5))\n",
    "ax.set_xlim(0,10000)\n",
    "usdf.price.hist(ax=ax, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "norm = cm.colors.Normalize(vmax=usdf.price.values.max(), vmin=usdf.price.values.min())\n",
    "cmap = cm.jet\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(frameon=False)\n",
    "plt.setp(ax, xticks=(), yticks=())\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.9,\n",
    "                wspace=0.0, hspace=0.0)\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1],\n",
    "        c=usdf.price.values, marker=\"x\", cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import  hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering\n",
    "X = tfidf.todense()\n",
    "threshold = 0.1\n",
    "Z = hierarchy.linkage(X,\"average\", metric=\"cosine\")\n",
    "#Clustering\n",
    "maxclust = 20\n",
    "C = hierarchy.fcluster(Z, maxclust, criterion=\"maxclust\")\n",
    "#C = hierarchy.fcluster(Z, threshold, criterion=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdf['clusters'] = C\n",
    "usdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_hiprice = FreqDist(word for word in ' '.join(usdf[usdf['price']>100]['adesc'].values).split() if not word.isnumeric())\n",
    "fdist_hiprice.pprint(maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,10)) \n",
    "plt.sca(ax)\n",
    "fdist_hiprice.plot(20, cumulative=False)\n",
    "fig.savefig('disthiprice.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,10)) \n",
    "plt.sca(ax)\n",
    "fdist_loprice.plot(20,cumulative=False)\n",
    "fig.savefig('distloprice.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_loprice = FreqDist(word for word in ' '.join(usdf[usdf['price']<25]['desc'].values).split() if not word.isnumeric())\n",
    "fdist_loprice.pprint(maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = usdf['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_rf = RandomForestRegressor(n_estimators=20, max_depth=None,min_samples_split=2, random_state=2, oob_score=True)\n",
    "regr_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf = regr_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X!=tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.square(y_rf-y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeby = np.zeros(len(usdf))\n",
    "eps = 1.0\n",
    "for index, row in usdf.iterrows():\n",
    "    if(index<len(usdf)-2):\n",
    "        i2 = index+1\n",
    "        row2=usdf.iloc[i2]\n",
    "        while(row['clusters']==row2['clusters']):\n",
    "            #print(row[['price','title']], row2[['price','title']])\n",
    "            if (np.abs(float(row['price'])-float(row2['price']))<eps):\n",
    "                closeby[i2]=1\n",
    "            if(i2<len(usdf)-1): \n",
    "                i2+=1\n",
    "                row2=usdf.iloc[i2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(closeby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(C)-len(np.unique(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdf.groupby('clusters')['price'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets have 20 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering\n",
    "maxclust = 20\n",
    "C20 = hierarchy.fcluster(Z, maxclust, criterion=\"maxclust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(C20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdf['c20'] = C20\n",
    "usdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overview'].apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'vintage' in ' '.join(['\\n    Vintage item\\n', '\\n    Favorited by: ', '\\n', '\\n        Gift wrapping and message available\\n        ', '\\n    ']).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.findall(r'\\d{4}',' '.join(['\\n    Vintage item \\n', '\\n    Favorited by: ', '\\n', '\\n        Gift wrapping and message available\\n        ', '\\n    ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overview'].apply(lambda x: int('handmade' in ' '.join(x).lower() or 'hand-made' in ' '.join(x).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdf['handmade'] = usdf['overview'].apply(lambda x: int('handmade' in ' '.join(x).lower() or 'hand-made' in ' '.join(x).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_materials(ov):\n",
    "    l = [re.sub(r\"[^a-zA-Z\\d\\s]\", '', x).lower().replace('materials','').replace('material','').strip() for x in ov if 'materials' in x.lower() or 'material' in x.lower()] \n",
    "    return l[0] if len(l)>0 else np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overview'].apply(extract_materials)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_materials(ov):\n",
    "    l = [re.sub(r\"[^a-zA-Z\\d\\s]\", '', x).lower().replace('materials','').replace('material','').strip() for x in ov if 'materials' in x.lower() or 'material' in x.lower()] \n",
    "    return l[0] if len(l)>0 else np.nan\n",
    "    \n",
    "usdf['materials'] = usdf['overview'].apply(extract_materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
